{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier on Iris Dataset\n",
    "<br>张栋玮 19373703 <a href=\"http://github.com/ZhangDw529/PythonProjects\">Open in GITHUB</br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "<br>Naive Bayes is a generative classification algorithm which is based on bayesian theorem and conditional independence assumption. By using bayesian theorem, we can compute posterior probability with prior probabilities and observations. Bayesian theorem is shown as follows.</br>\n",
    "<img src='./pic/bayes.jpg' width=400 height=100 >\n",
    "<br>Let the series of decision actions as ${a_1,a_2,..,a_c}$, the conditional risk of decision action $a_i$ can be computed by</br>\n",
    "<img src='./pic/risk.jpg' width=400 height=100>\n",
    "<br>Thus the minimum risk Bayesian decision can be found as</br>\n",
    "<img src='./pic/arg.jpg' width=400 height=100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Algorithm\n",
    "## 1.1 Data Preprocess\n",
    "Here I load the Iris dataset from sklearn.datasets. Then split it into train set and test set with $test\\_size=0.2,random\\_state=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "def load_data():\n",
    "    iris = datasets.load_iris()\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=3)\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Bayes Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>This is the python class named bayes. It contains four parts with details in comments.</br>\n",
    "- Initialization and training\n",
    "- Predictions\n",
    "- Computation of accuracy\n",
    "- Data print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayes():\n",
    "\n",
    "    # Initialize and train\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.categories = len(np.unique(y_train))  # 3 classes in the dataset\n",
    "        self.total_col = x_train.shape[1]   # Number of Attributes used\n",
    "        self.partial = []   # Split proportion\n",
    "        self.mean = np.zeros([self.categories,self.total_col]) # Initialization\n",
    "        self.var = np.zeros([self.categories,self.total_col]) \n",
    "\n",
    "        # Compute the proportion, variance and mean of each class       \n",
    "        for i in range(self.categories):\n",
    "            temp = x_train[np.nonzero(i==y_train)] # Select i_th class\n",
    "            self.partial.append(len(temp)/len(x_train))\n",
    "            self.mean[i,:] = np.mean(temp,axis=0,keepdims=True)\n",
    "            self.var[i,:] = np.var(temp,axis=0,keepdims=True)\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    def predict(self, x_test,y_test):\n",
    "        result = []\n",
    "        eps = 1e-10  \n",
    "        for i in x_test:\n",
    "            x = np.tile(i,(3,1))\n",
    "            \n",
    "            # Compute the Gaussian pdf\n",
    "            num = -(x-self.mean+eps)**2\n",
    "            den = 2*self.var+eps\n",
    "            _exp = np.exp(num/den)\n",
    "            # _exp = np.exp(-(x-self.mean)**2/(2*self.var+eps))\n",
    "            \n",
    "            # Compute the posterior possibilities\n",
    "            p = _exp/(np.sqrt(2*np.pi)*self.var+eps)\n",
    "            # Change the possibilities into log() mode\n",
    "            log_p = np.sum(np.log(p),axis=1) \n",
    "            prob = np.log(self.partial)+log_p\n",
    "            result.append(np.argmax(prob))\n",
    "        return result\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    def acc(self, y_test, y_pred):\n",
    "        acc = np.count_nonzero(y_test==y_pred)\n",
    "        return acc/len(y_pred)\n",
    "    \n",
    "    # Print parameters\n",
    "    def printPara(self):\n",
    "        print(f\"The dataset has {self.categories} categories and {self.total_col} attributes.\")\n",
    "        print(\"Proportion of each class:\")\n",
    "        print(self.partial)\n",
    "        print(\"Mean:\")\n",
    "        print(self.mean)\n",
    "        print(\"Var:\")\n",
    "        print(self.var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test\n",
    "<br>In this part, I first </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3 categories and 4 attributes.\n",
      "Proportion of each class:\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "Mean:\n",
      "[[5.03   3.4325 1.465  0.2375]\n",
      " [5.93   2.7875 4.2675 1.335 ]\n",
      " [6.5525 2.9875 5.5325 2.01  ]]\n",
      "Var:\n",
      "[[0.1011     0.13219375 0.032775   0.01134375]\n",
      " [0.2351     0.10009375 0.21819375 0.040275  ]\n",
      " [0.38749375 0.10309375 0.28519375 0.0649    ]]\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "x_train,x_test,y_train,y_test=load_data()\n",
    "TotalAttr = Bayes(x_train,y_train)\n",
    "TotalAttr.printPara()\n",
    "y_pred = TotalAttr.predict(x_test,y_test)\n",
    "acc = TotalAttr.acc(y_test,y_pred)\n",
    "print(f'Accuracy: {acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3 categories and 2 attributes.\n",
      "Proportion of each class:\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "Mean:\n",
      "[[1.465  0.2375]\n",
      " [4.2675 1.335 ]\n",
      " [5.5325 2.01  ]]\n",
      "Var:\n",
      "[[0.032775   0.01134375]\n",
      " [0.21819375 0.040275  ]\n",
      " [0.28519375 0.0649    ]]\n",
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=load_data()\n",
    "# Take attribute 3 and 4 into consideration\n",
    "x_train = x_train[:,2:]\n",
    "x_test = x_test[:,2:]\n",
    "Attr34 = Bayes(x_train,y_train)\n",
    "Attr34.printPara()\n",
    "y_pred = Attr34.predict(x_test,y_test)\n",
    "acc = Attr34.acc(y_test,y_pred)\n",
    "print(f'Accuracy: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "<br>[1] Statistical Pattern Recognition Lab, SASEE</br>\n",
    "<br>[2] <a href=\"https://blog.csdn.net/Happy_change/article/details/117226036\">朴素贝叶斯算法</a></br>\n",
    "<br>[3] <a href=\"https://blog.csdn.net/weixin_46302044/article/details/117399359\">朴素贝叶斯处理鸢尾花数据集分类</a></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
